!pip install dask
!pip install -U scikit-learn
!pip install shap
!pip install --user pandas -U
!pip install --user catboost


# -- необязательно --
#!pip install ipywidgets
#!pip install jupyter_contrib_nbextensions
#!jupyter contrib nbextension install --user
#!jupyter nbextension enable --py widgetsnbextension #чтобы работал параметр plot для catboost

#

import numpy as np
import pandas as pd
import time
from datetime import datetime
import dask.dataframe as dd
from dask.diagnostics import ProgressBar
from dask.diagnostics import Profiler
from dask.diagnostics import ResourceProfiler
import gc
import catboost

from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler, RobustScaler, LabelEncoder, OneHotEncoder
from sklearn.pipeline import make_pipeline
from sklearn.metrics import precision_score, recall_score, auc, accuracy_score, roc_auc_score,f1_score,log_loss,
                            classification_report, roc_curve

import seaborn as sns
import matplotlib.pyplot as plt
import pickle


import jaydebeapi
import subprocess
from statistics import mean

path_dmarts_for_score = 'homejovyanworkshareDCIDBScore_modelsDMARTS_FOR_SCORE'
path_score_models = 'homejovyanworkshareDCIDBScore_models'
path_function = 'homejovyanworkshareDCIDBScore_modelsFunction'
path_folder = 'homejovyanworkshareDCIDBScore_modelsCC'
name_df_pikle = path_folder+'df_DMART_FOR_SCORE_NEW_2022_08_01.pkl'

import sys  
sys.path.append(path_function)  
#'homejovyanworkMy_lib'
from func_for_dmart_score import  

#Параметры запуска
WORK_MODE = 1 #1 - Есть реальный таргет, 2 - Нет реального таргета, режим предсказания

pbar = ProgressBar()
pbar.register()

# print('CatBoostClassifier, cat_v2_imp. Загрузка модели в формате pkl')
# pkl_filename = cat_v2_imp_columns.pkl
# with open(pkl_filename, 'rb') as file
#     cat2_imp_load = pickle.load(file)
# print('Ok')

# print('CatBoostClassifier, cat_v3_imp. Загрузка модели в формате pkl')
# pkl_filename = cat_v3_imp_columns.pkl
# with open(pkl_filename, 'rb') as file
#     cat3_imp_load = pickle.load(file)
# print('Ok')

print('CatBoostClassifier, cat_v2_imp. Загрузка модели в формате catboost')
cat4_imp_load = catboost.CatBoostClassifier()
cat4_imp_load.load_model(сс_cat_imp_columns.cbm)
print('ok')

name_file_imp_col = 'cc_cat_list_feature_imp.txt'
print(f'Загрузка списка важных полей {name_file_imp_col}')
with open(name_file_imp_col, 'r') as file
    list_cat_v2_imp = file.readlines()
#удаляем сивмолы перевода на новую строку
list_cat_v2_imp = [x.strip() for x in list_cat_v2_imp]
print(f'Кол-во важных полей {len(list_cat_v2_imp)}')

# В список важных полей входит поле rf, которое является вычисляемым от поля code. Поэтому rf нужно удалить из списка перед загрузкой данных,
# а после загрузки добавить в начало, в соотв. с моделью. Т.е. поле rf должно быть в списке первым.
list_cat_v2_imp_mod = list_cat_v2_imp[1] #берем все значения кроме первого, нумерация с 0
list_name_imp_columns = ['code'] + list_cat_v2_imp_mod #добавляем code

#Загрузка витрины для выставления скоров
name_file_dmart = 'homejovyanworkshareDCIDBScore_modelsDMARTS_FOR_SCOREDMART_FOR_SCORE_NEW_2022_09_01.csv'
df_imp_cat_v2 = read_big_csv_imp_columns(name_file_dmart,
                                         list_name_imp_columns, dtype_dmart_for_score, list_not_int_dmart_for_score)

df_imp_cat_v2.head()

#добавляем поле rf
df_imp_cat_v2['rf'] = pd.to_numeric(df_imp_cat_v2.code.str[2], downcast='integer')

#удаляем поле code
code_imp = df_imp_cat_v2['code']
df_imp_cat_v2.drop(['code'], axis=1, inplace=True)

#преобразуем df_imp_cat_v2, порядок полей должен совпадать с df_imp_cat_v2
df_imp_cat_v2 = pd.DataFrame(df_imp_cat_v2, columns=list_cat_v2_imp)

gc.collect()

df_imp_cat_v2.head()

#предсказываем
y_score_imp = cat4_imp_load.predict_proba(df_imp_cat_v2)[,1]

#Создаем датафрейм с предсказаниями модели, делим все данные на 10 бинов от 1 до 10
df_bin = pd.DataFrame({'code' code_imp, 'y_score' y_score_imp})
df_bin['bin_int'] = pd.cut(df_bin['y_score'], bins=10, labels=list(range(1, 11)))

#Смотрим на распределение предсказаний по бинам
df_bin.bin_int.value_counts().sort_index(ascending=False)

#df_bin[df_bin.bin_int=7].count()

print(f'Кол-во строк в данных {len(df_bin)}')

print(f'Кол-во таргетов {len(df_y)}')

if WORK_MODE == 1
    #загружаем реальный таргет
    df_y = pd.read_csv('CC_TARGETS_sep2022.csv', encoding='utf', sep=',', dtype={'target''uint8'})
    #добавление от меня, т.к. в CC_TARGETS_AUG2022.csv нет поля таргет
    df_y['target'] = 1
    df_y['target'] = df_y['target'].astype('uint8')
    # добавление закончено
    df_bin = df_bin.merge(df_y, on='code', how='left')
    df_bin.loc[pd.isnull(df_bin.target), 'target'] = 0
    df_bin['target'] = df_bin['target'].astype('uint8')
    print(len(df_bin[df_bin.target==1]), len(df_bin))
    real_rate_upd = len(df_bin[df_bin.target==1])  len(df_bin) #пересчет real_rate
    df_bin['Adj_P1_upd'] = (1(1 + ((1real_rate_upd) - 1)  ((10.5) - 1)  ((1df_bin.y_score) - 1)))
    print('roc-auc', roc_auc_score(df_bin.target, y_score_imp))
else
    real_rate = 5966  13264763 #реальный отклик по проскоренной базе на месяце обучения 09.2022
    df_bin['Adj_P1'] = (1(1 + ((1real_rate) - 1)  ((10.5) - 1)  ((1df_bin.y_score) - 1)))
    #7107
    


#df_y.target.info() посмотреть формат колонки

real_rate_upd

df_bin

print(len(df_bin[df_bin.target==1]), len(df_bin)), len(df_y)

if WORK_MODE == 1
    df_stat = df_bin.groupby(by=['bin_int']).agg({'target'['sum', 'mean', 'count'], 
                                                  'y_score'['sum', 'mean'], 
                                                  #'Adj_P1'['sum', 'mean'],
                                                  'Adj_P1_upd'['sum', 'mean'] 
                                                 })
    print(df_stat)
    # убираем мультииндекс
    df_stat.columns = [c[0]+'_'+c[1] for c in df_stat.columns]
    print(df_stat.columns)
    # добавляем месяц предсказания и название модели
    df_stat['Report_date'] = '2022.09.01'
    df_stat['model_name'] = 'CC, cat2_imp'
    df_stat = df_stat.reset_index()
    df_stat.rename(columns={'bin_int''Бины', 
                            'target_sum''Факт. отклик', 
                            'target_count''Кол-во клиентов', 
                            'Adj_P1_upd_sum' 'Прогноз',
                            'y_score_mean''Средний модельный скор',
                            'Adj_P1_upd_mean''Средний приведенный скор'}, inplace=True)
    stats_columns = ['Report_date', 'Бины', 'Кол-во клиентов', 'Факт. отклик', 'Прогноз', 'Средний модельный скор', 
                     'Средний приведенный скор', 'model_name']
    df_stat = df_stat[stats_columns]
    df_stat['Факт. отклик'] = df_stat['Факт. отклик'].astype(int)
    df_stat['Прогноз'] = df_stat['Прогноз'].round(0).astype(int)
    print(f'Adj_P1_upd {int(df_bin.Adj_P1_upd.sum())}, target {df_bin.target.sum()}')
    # сохраняем рез-т в excel
    df_stat.to_excel('statist_model_cat2_imp_month9.xlsx', index=False, encoding='utf')
    
    

#Закомментировал, пока не используется
# if WORK_MODE == 1
#     #предсказываем, 2-ая модель
#     y_score_imp2 = cat3_imp_load.predict_proba(df_imp_cat_v2)[,1]
#     df_bin2 = pd.DataFrame({'code' code_imp, 'y_score' y_score_imp2})
#     df_bin2['bin_int'] = pd.cut(df_bin2['y_score'], bins=10, labels=list(range(1, 11)))
#     df_bin2 = df_bin2.merge(df_y, on='code', how='left')
#     df_bin2.loc[pd.isnull(df_bin2.target), 'target'] = 0
#     df_bin2['target'] = df_bin2['target'].astype('uint8')
#     print(df_bin2.bin_int.value_counts().sort_index(ascending=False))
#     print(df_bin2[df_bin2.bin_int=7].count())
#     df_bin2['Adj_P1_upd'] = (1(1 + ((1real_rate_upd) - 1)  ((10.5) - 1)  ((1df_bin2.y_score) - 1)))
#     print('roc-auc', roc_auc_score(df_bin2.target, y_score_imp2))
#     df_stat2 = df_bin2.groupby(by=['bin_int']).agg({'target'['sum', 'mean', 'count'],
#                                                     'y_score'['sum', 'mean'], 
#                                                     #'Adj_P1'['sum', 'mean'],
#                                                     'Adj_P1_upd'['sum', 'mean']
#                                                })
#     # убираем мультииндекс
#     df_stat2.columns = [c[0]+'_'+c[1] for c in df_stat2.columns]
#     # добавляем месяц предсказания и название модели
#     df_stat2['Report_date'] = '2022.08.01'
#     df_stat2['model_name'] = 'CASH, cat3_imp'
#     df_stat2 = df_stat2.reset_index()
#     df_stat2.rename(columns={'bin_int''Бины', 
#                             'target_sum''Факт. отклик', 
#                             'target_count''Кол-во клиентов', 
#                             'Adj_P1_upd_sum' 'Прогноз',
#                             'y_score_mean''Средний модельный скор',
#                             'Adj_P1_upd_mean''Средний приведенный скор'}, inplace=True)

#     stats_columns = ['Report_date', 'Бины', 'Кол-во клиентов', 'Факт. отклик', 'Прогноз', 'Средний модельный скор', 
#                      'Средний приведенный скор', 'model_name']
#     df_stat2 = df_stat2[stats_columns]
#     df_stat2['Факт. отклик'] = df_stat2['Факт. отклик'].astype(int)
#     df_stat2['Прогноз'] = df_stat2['Прогноз'].round(0).astype(int)
#     print(f'Adj_P1_upd {int(df_bin2.Adj_P1_upd.sum())}, target {df_bin2.target.sum()}')
#     df_stat2.to_excel('statist_model_cat3_imp_month8.xlsx', index=False, encoding='utf')

if WORK_MODE == 1
    cat2_imp_load_auc = roc_auc_score(df_bin.target, y_score_imp)
    
    #cat3_imp_load_auc = roc_auc_score(df_bin2.target, y_score_imp2)

    plt.figure(figsize=(10,6))
    plt.plot(roc_curve(df_bin.target, y_score_imp)[2], label='cat2_imp_load_auc={.5f}'.format(cat2_imp_load_auc))
    #plt.plot(roc_curve(df_bin2.target, y_score_imp2)[2], label='cat3_imp_load_auc={.5f}'.format(cat3_imp_load_auc))
    legend_box = plt.legend(fontsize='large', framealpha=1).get_frame()
    legend_box.set_facecolor(white)
    legend_box.set_edgecolor(black)
    plt.plot(np.linspace(0,1,100), np.linspace(0,1,100))
    plt.show()

if WORK_MODE == 2
    #Нет реального таргета
    df_bin['PRODUCT'] = 'CASH'
    df_bin['MODEL'] = 1 #Сквозная нумерация, начинается с 1, справочник
    df_bin.rename(columns={'code''CODE', 'y_score''SCORE', 'Adj_P1''SCORE_adj', 'bin_int''SCORE_BIN'}, inplace=True)
    df_bin=df_bin[['CODE', 'PRODUCT', 'SCORE', 'SCORE_adj', 'SCORE_BIN', 'MODEL']]
    print(df_bin)
    name_file_predict = 'predict_CASH_' + name_file_dmart[-14]
    df_bin.to_csv(name_file_predict, index=False, encoding='utf')
    print()
    df_stat = df_bin.groupby(by=['SCORE_BIN']).agg({'SCORE_BIN'['count'], 
                                                  'SCORE'['mean'], 
                                                  'SCORE_adj'['mean']
                                                   })
    df_stat.columns = [c[0]+'_'+c[1] for c in df_stat.columns]
    print(df_stat)
    name_file_stat = 'stat_CASH_' + name_file_dmart[-14]
    df_stat.to_csv(name_file_stat, index=False, encoding='utf')
    

pbar.unregister()

# Connection param
driver = 'com.cloudera.hive.jdbc41.HS2Driver'
url = 'jdbchive2sgo-hd015.go.rshbank.ru10000default'
driver_arg = {
    'tez.queue.name' 'rshb_users',
    'AuthMech' '1',
    'Host' 'sgo-hd015.go.rshbank.ru',
    'Port' '10000',
    'KrbHostFQDN' 'sgo-hd015.go.rshbank.ru',
    'KrbRealm' 'GO.RSHBANK.RU',
    'KrbServiceName' 'hive'}
jarFile = ['tmpjarsHiveJDBC41.jar']

def krbauth(username, password)
    realm='@GO.RSHBANK.RU'
    cmd = ['kinit', '-c', 'tmpkrb5cc_1000', username+realm]
    success = subprocess.run(cmd, input=password.encode(), stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL).returncode
    return not bool(success)

def as_pandas_DataFrame(cursor)
    names = [metadata[0] for metadata in cursor.description]
    return pd.DataFrame([dict(zip(names, row)) for row in cursor.fetchall()], columns=names)

# Create user's token to DataLake
if WORK_MODE == 2
    with open('homejovyanworkMy_paswpasw.txt', 'r') as f
        login, passw = f.readline().split()
    if krbauth(login, passw)
        print('Succesfully Logged in!')
    else
        print('Incorrect Login!')

    # Create connection
    conn = jaydebeapi.connect(
        jclassname=driver
        ,url=url
        ,driver_args=driver_arg
        ,jars=jarFile)

    # Get cursor to interact with the SQL engine
    cursor = conn.cursor()

name_file_dmart[-14-4]

table_name = 'sandbox_dcidb.smn_score_mart_' + name_file_dmart[-14-4]
cursor.execute(f'create table if not exists {table_name}(CODE varchar(20), PRODUCT varchar(6), SCORE FLOAT, SCORE_adj FLOAT, SCORE_BIN SMALLINT, MODEL SMALLINT)')


#table_name

#cursor.execute(f'drop table {table_name}')

if WORK_MODE == 2
    global_start_time = datetime.now()
    print(f'Начинаю запись данных в HIVE. Тек.время {global_start_time.strftime(%Y-%m-%d %H%M%S)}')
    chunksize = 50000
    #schema_table = 'sandbox_dcidb.smn_test'
    sql_exceptions = []
    row_n = 0
    df_len = len(df_bin)
    cols_names_list = df_bin.columns.values.tolist()
    cols_names = f'({ , .join(cols_names_list) })'
    list_time_save = []
    while row_n  df_len       
        start_time = time.time()
        beginrow = row_n
        endrow = df_len if (row_n + chunksize)  df_len else row_n + chunksize 
        # Extract the chunk
        values = df_bin.values[beginrow  endrow].tolist()
        values_params = '('+, .join('' for i in cols_names_list)+')'
        sql = fINSERT INTO {table_name} {cols_names} VALUES {values_params}
        #print(sql)
        #print(values)
        try
            cursor.executemany(sql, values)
            conn.commit()
        except Exception as e
            sql_exceptions.append((beginrow,endrow, e))
        row_n = endrow
        time_save = round(time.time() - start_time, 2)
        list_time_save.append(time_save)
        print(f'Записано {row_n} записей, время записи последней части данных из {chunksize} записей - {time_save} секунд')
    conn.close()
    print(f'Среднее время записи порции данных из {chunksize} строк - {round(mean(list_time_save), 2)} секунд')
    global_end_time = datetime.now()
    print(f'Закончил работу. Общее время операции {global_end_time - global_start_time}')